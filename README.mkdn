## Analogical Modeling Weka Plugin

This project is a Weka plugin containing state-of-the-art algorithms for classification using [analogical modeling](https://en.wikipedia.org/wiki/Analogical_modeling).

### Analogical Modeling
Analogical Modeling (or AM) was developed as an exemplar-based approach to modeling language usage, and has also been found useful in modeling other "sticky" phenomena. AM is especially suited to this because it predicts probabilistic occurrences instead of assigning static labels for instances.

AM was not designed to be a classifier, but as a cognitive theory explaining variation in human behavior. As such, though in practice it is often used like any other machine learning classifier, there are fine theoretical points in which it differs. As a theory of human behavior, much of the value in its predictions lies in matching observed human behavior, including non-determinism and degradations in accuracy caused by paucity of data.

The AM algorithm could be called a probabilistic, instance-based classifier. However, the probabilities given for each classification are not degrees of certainty, but actual probabilities of occurring in real usage. AM models "sticky" phenomena as being intrinsically sticky, not as deterministic phenomena that just require more data to be predicted perfectly.

Though it is possible to choose an outcome probabilistically, in practice users are generally interested in either the full predicted probability distribution or the outcome with the highest probability.

AM practitioners generally use terminology taken from statistics, most of which has equivalent terminology used by computer scientists (and most machine learning frameworks in general). Examples are 'exemplar' (training instance), 'outcome' (class label), and 'variable' (feature). This software uses the CS terminology internally, but (TODO) user-facing reports use the AM terminology.

The running time for analogical modeling is exponential in nature and practice, and thus it is not suitable for very large datasets; exact calculation becomes impractical after about 50 features.

### Features

As an evolving project, the most important design principle has been modularity and ease of experimentation with core algorithms. As such, the system is able to adapt for data of different cardinalities:

* Context labels scale up from `int`s to `long`s and `BigInteger`s
* Very small vectors are placed in a single lattice
* Larger vectors are placed in a distributed lattice, with the number of lattices increasing with size
* Very large vectors (50 or more features) are classified approximately using Monte Carlo simulation

Some algorithmic improvements have been made to the distributed lattice and approximate lattice filling algorithms. Concurrency is also used extensively so that 8 CPU cores will fill lattices roughly 8 times faster, etc.

### Building
This project is managed with [Gradle](https://gradle.org/), which will need to be installed to build from the terminal. The following build commands are then available:

    # compile Java source into a jar
    gradle build
    # run unit tests
    gradle test
    # generate HTML documentation
    gradle javadoc
    # build the project archive for release as a Weka plugin
    gradle dist
    # generate an Eclipse project
    gradle eclipse
    # bump the minor version number (update Description.props, git commit/tag/push)
    gradle bumpMinor

### Releasing

To release a new version of the plugin:

* run `gradle bumpMinor`
* create a new release on GitHub corresponding to the new tag
* upload the distribution to the release
* send the new Description.props file to Mark Hall

### Running

Under construction; try testing AnalogicalModeling.java with `-t data/ch3example.arff -x 5`.

### License

Released under the Apache 2.0 license (see the LICENSE file for details). Copyright Nathan Glenn, 2014.

### See Also
https://metacpan.org/pod/Algorithm::AM
